{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3819f420",
   "metadata": {},
   "source": [
    "# Benchmark of existing approaches for detecting machine-generated text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bdd5a04",
   "metadata": {},
   "source": [
    "## Contents \n",
    "1. [Solaiman](#Solaiman)\n",
    "    1. [Install dependencies](#Install-dependencies)\n",
    "    1. [Solaiman Code](#Solaiman-Code)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9faa5fa6",
   "metadata": {},
   "source": [
    "## Solaiman\n",
    "\n",
    "_Irene Solaiman, Miles Brundage, Jack Clark, Amanda Askell, Ariel Herbert-Voss, Jeff Wu, Alec Radford,\n",
    "Gretchen Krueger, Jong Wook Kim, Sarah Kreps, Miles McCain, Alex Newhouse, Jason Blazakis, Kris McGuffie, and Jasmine Wang. 2019. Release strategies and the social impacts of language models._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63d58d8",
   "metadata": {},
   "source": [
    "### Install dependencies\n",
    "Dependencies from: [https://github.com/HendrikStrobelt/detecting-fake-text/blob/master/requirements.txt](detecting-fake-text/requirements.txt)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a177608",
   "metadata": {},
   "source": [
    "### Solaiman Code\n",
    "Source code: [https://github.com/openai/gpt-2-output-dataset/tree/master/detector](https://github.com/openai/gpt-2-output-dataset/tree/master/detector)\n",
    "\n",
    "Logic extracted form `server.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4d3ba72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "assert transformers.__version__ == '2.9.1', \"Use transformers 2.9.1. It is available in the conda environment transf291\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "071cd47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaForSequenceClassification, RobertaTokenizer\n",
    "import json\n",
    "import torch\n",
    "from urllib.parse import urlparse, unquote"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1488ca20",
   "metadata": {},
   "source": [
    "#### Select model to use RoBERTa base or large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9a88c141",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name = 'roberta-large'\n",
    "model_name = 'roberta-base'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07017558",
   "metadata": {},
   "source": [
    "#### Define model, tokenizer, and basic functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b4935ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RobertaForSequenceClassification.from_pretrained(model_name)\n",
    "tokenizer = RobertaTokenizer.from_pretrained(model_name)\n",
    "device='cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ed883728",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(query):\n",
    "    tokens = tokenizer.encode(query)\n",
    "    all_tokens = len(tokens)\n",
    "    tokens = tokens[:tokenizer.max_len - 2]\n",
    "    used_tokens = len(tokens)\n",
    "    tokens = torch.tensor([tokenizer.bos_token_id] + tokens + [tokenizer.eos_token_id]).unsqueeze(0)\n",
    "    mask = torch.ones_like(tokens)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(tokens.to(device), attention_mask=mask.to(device))[0]\n",
    "        probs = logits.softmax(dim=-1)\n",
    "\n",
    "    fake, real = probs.detach().cpu().flatten().numpy().tolist()\n",
    "\n",
    "    return json.dumps(dict(\n",
    "        all_tokens=all_tokens,\n",
    "        used_tokens=used_tokens,\n",
    "        real_probability=real,\n",
    "        fake_probability=fake\n",
    "    ))\n",
    "\n",
    "\n",
    "def initialize(checkpoint):\n",
    "#     if checkpoint.startswith('gs://'):\n",
    "#         print(f'Downloading {checkpoint}', file=sys.stderr)\n",
    "#         subprocess.check_output(['gsutil', 'cp', checkpoint, '.'])\n",
    "#         checkpoint = os.path.basename(checkpoint)\n",
    "#         assert os.path.isfile(checkpoint)\n",
    "\n",
    "    print(f'Loading checkpoint from {checkpoint}')\n",
    "    data = torch.load(checkpoint, map_location='cpu')\n",
    "    model.load_state_dict(data['model_state_dict'])\n",
    "    model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd3264ae",
   "metadata": {},
   "source": [
    "#### Download finetuned model and load it into RoBERTa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "713a687e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://openaipublic.azureedge.net/gpt-2/detector-models/v1/detector-base.pt\n",
    "# !wget https://openaipublic.azureedge.net/gpt-2/detector-models/v1/detector-large.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ba08258f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint from detector-base.pt\n"
     ]
    }
   ],
   "source": [
    "# initialize('detector-large.pt')\n",
    "initialize('detector-base.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a46d5d62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"all_tokens\": 4, \"used_tokens\": 4, \"real_probability\": 0.5563012361526489, \"fake_probability\": 0.4436987340450287}'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(\"hello world\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:transf291] *",
   "language": "python",
   "name": "conda-env-transf291-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
