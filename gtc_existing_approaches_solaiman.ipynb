{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3819f420",
   "metadata": {},
   "source": [
    "# Benchmark of existing approaches for detecting machine-generated text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bdd5a04",
   "metadata": {},
   "source": [
    "## Contents \n",
    "1. [Solaiman](#Solaiman)\n",
    "    1. [Install dependencies](#Install-dependencies)\n",
    "    1. [Solaiman Code](#Solaiman-Code)\n",
    "2. [Data Exploration](#Data-exploration)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9faa5fa6",
   "metadata": {},
   "source": [
    "## Solaiman\n",
    "\n",
    "_Irene Solaiman, Miles Brundage, Jack Clark, Amanda Askell, Ariel Herbert-Voss, Jeff Wu, Alec Radford,\n",
    "Gretchen Krueger, Jong Wook Kim, Sarah Kreps, Miles McCain, Alex Newhouse, Jason Blazakis, Kris McGuffie, and Jasmine Wang. 2019. Release strategies and the social impacts of language models._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63d58d8",
   "metadata": {},
   "source": [
    "### Install dependencies\n",
    "Dependencies from: [https://github.com/HendrikStrobelt/detecting-fake-text/blob/master/requirements.txt](detecting-fake-text/requirements.txt)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a177608",
   "metadata": {},
   "source": [
    "### Solaiman Code\n",
    "Source code: [https://github.com/openai/gpt-2-output-dataset/tree/master/detector](https://github.com/openai/gpt-2-output-dataset/tree/master/detector)\n",
    "\n",
    "Logic extracted form `server.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c4d3ba72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "assert transformers.__version__ == '2.9.1', \"Use transformers 2.9.1. It is available in the conda environment transf291\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "071cd47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaForSequenceClassification, RobertaTokenizer\n",
    "import json\n",
    "import torch\n",
    "from urllib.parse import urlparse, unquote"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1488ca20",
   "metadata": {},
   "source": [
    "#### Select model to use RoBERTa base or large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "9a88c141",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'roberta-large'\n",
    "#model_name = 'roberta-base'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07017558",
   "metadata": {},
   "source": [
    "#### Define model, tokenizer, and basic functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "b4935ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RobertaForSequenceClassification.from_pretrained(model_name)\n",
    "tokenizer = RobertaTokenizer.from_pretrained(model_name)\n",
    "device='cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "ed883728",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(query):\n",
    "    tokens = tokenizer.encode(query)\n",
    "    all_tokens = len(tokens)\n",
    "    tokens = tokens[:tokenizer.max_len - 2]\n",
    "    used_tokens = len(tokens)\n",
    "    tokens = torch.tensor([tokenizer.bos_token_id] + tokens + [tokenizer.eos_token_id]).unsqueeze(0)\n",
    "    mask = torch.ones_like(tokens)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(tokens.to(device), attention_mask=mask.to(device))[0]\n",
    "        probs = logits.softmax(dim=-1)\n",
    "\n",
    "    fake, real = probs.detach().cpu().flatten().numpy().tolist()\n",
    "\n",
    "    # Original: \n",
    "#    return json.dumps(dict(\n",
    "#         all_tokens=all_tokens,\n",
    "#         used_tokens=used_tokens,\n",
    "#         real_probability=real,\n",
    "#         fake_probability=fake\n",
    "#     ))\n",
    "\n",
    "# Changed to return only the binary classification result. 1 if sentence is likely machine-generated.\n",
    "    return (fake > 0.5, fake, real)\n",
    "\n",
    "def initialize(checkpoint):\n",
    "#     if checkpoint.startswith('gs://'):\n",
    "#         print(f'Downloading {checkpoint}', file=sys.stderr)\n",
    "#         subprocess.check_output(['gsutil', 'cp', checkpoint, '.'])\n",
    "#         checkpoint = os.path.basename(checkpoint)\n",
    "#         assert os.path.isfile(checkpoint)\n",
    "\n",
    "    print(f'Loading checkpoint from {checkpoint}')\n",
    "    data = torch.load(checkpoint, map_location='cpu')\n",
    "    model.load_state_dict(data['model_state_dict'])\n",
    "    model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd3264ae",
   "metadata": {},
   "source": [
    "#### Download finetuned model and load it into RoBERTa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "713a687e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://openaipublic.azureedge.net/gpt-2/detector-models/v1/detector-base.pt\n",
    "# !wget https://openaipublic.azureedge.net/gpt-2/detector-models/v1/detector-large.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "ba08258f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint from detector-large.pt\n"
     ]
    }
   ],
   "source": [
    "initialize('detector-large.pt')\n",
    "# initialize('detector-base.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "a46d5d62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, 0.7026421427726746, 0.29735779762268066)"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(\"hello world\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56bfaa2d",
   "metadata": {},
   "source": [
    "## Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "67e27aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a3f47d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"./data\"\n",
    "datasets = sorted([f for f in os.listdir(data_path) if os.path.isfile(os.path.join(data_path, f))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "97f16b7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['large-762M-k40.test.jsonl',\n",
       " 'large-762M-k40.train.jsonl',\n",
       " 'large-762M-k40.valid.jsonl',\n",
       " 'large-762M.test.jsonl',\n",
       " 'large-762M.train.jsonl',\n",
       " 'large-762M.valid.jsonl',\n",
       " 'medium-345M-k40.test.jsonl',\n",
       " 'medium-345M-k40.train.jsonl',\n",
       " 'medium-345M-k40.valid.jsonl',\n",
       " 'medium-345M.test.jsonl',\n",
       " 'medium-345M.train.jsonl',\n",
       " 'medium-345M.valid.jsonl',\n",
       " 'small-117M-k40.test.jsonl',\n",
       " 'small-117M-k40.train.jsonl',\n",
       " 'small-117M-k40.valid.jsonl',\n",
       " 'small-117M.test.jsonl',\n",
       " 'small-117M.train.jsonl',\n",
       " 'small-117M.valid.jsonl',\n",
       " 'webtext.test.jsonl',\n",
       " 'webtext.train.jsonl',\n",
       " 'webtext.valid.jsonl',\n",
       " 'xl-1542M-k40.test.jsonl',\n",
       " 'xl-1542M-k40.train.jsonl',\n",
       " 'xl-1542M-k40.valid.jsonl',\n",
       " 'xl-1542M.test.jsonl',\n",
       " 'xl-1542M.train.jsonl',\n",
       " 'xl-1542M.valid.jsonl']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa87dcb3",
   "metadata": {},
   "source": [
    "### Human-written data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "c0eeaf64",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_hw_filename = 'webtext.train.jsonl'\n",
    "ds_hw = pd.read_json(os.path.join(data_path, ds_hw_filename), lines = True)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "28a90a5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1001 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.48 Seconds for a check with GPT-2\n",
      "machine generated? (False, 0.0001773454569047317, 0.9998226761817932)\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "payload = evaluate(ds_hw.iloc[20].text)\n",
    "end = time.time()\n",
    "print(\"{:.2f} Seconds for a check with GPT-2\".format(end - start))\n",
    "print(f\"machine generated? {payload}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d56b1ef",
   "metadata": {},
   "source": [
    "### Machine-generated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "1c4d1628",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_mg_filename = 'small-117M.train.jsonl'\n",
    "ds_mg = pd.read_json(os.path.join(data_path, ds_mg_filename), lines = True)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "90620ca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1024 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.46 Seconds for a check with GPT-2\n",
      "machine generated? (True, 0.9997071623802185, 0.0002927991736214608)\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "payload = evaluate(ds_mg.iloc[20].text)\n",
    "end = time.time()\n",
    "print(\"{:.2f} Seconds for a check with GPT-2\".format(end - start))\n",
    "print(f\"machine generated? {payload}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2e0ebc",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "### Auxiliary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "55e6eadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "def create_dataset(raw_data, is_machine_generated=True):\n",
    "    X = np.array(raw_data)\n",
    "    if is_machine_generated:\n",
    "        y = np.ones_like(X)\n",
    "    else:\n",
    "        y = np.zeros_like(X)\n",
    "    return pd.DataFrame(data={'X':X, 'y':y})\n",
    "\n",
    "def concat_and_shuffle(datasets):\n",
    "    return shuffle(pd.concat(datasets)).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "ccc870e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "def safe_macro_f1(y, y_pred):\n",
    "    \"\"\"\n",
    "    Macro-averaged F1, forcing `sklearn` to report as a multiclass\n",
    "    problem even when there are just two classes. `y` is the list of\n",
    "    gold labels and `y_pred` is the list of predicted labels.\n",
    "\n",
    "    \"\"\"\n",
    "    return f1_score(y, y_pred, average='macro', pos_label=None)\n",
    "\n",
    "def safe_accuracy(y, y_pred):\n",
    "    return accuracy_score(y, y_pred, normalize=True)\n",
    "\n",
    "def gtc_evaluate(\n",
    "        dataset,\n",
    "        model,\n",
    "        score_func=safe_accuracy):\n",
    "\n",
    "    # Predictions if we have labels:\n",
    "    preds = model.predict(dataset['X'])\n",
    "    if dataset['y'] is not None:\n",
    "        y = dataset['y'].tolist()\n",
    "        confusion = confusion_matrix(y, preds)\n",
    "        score = score_func(y, preds)\n",
    "        \n",
    "    # Return the overall scores and other experimental info:\n",
    "    return {\n",
    "        'model': model,\n",
    "        'predictions': preds, \n",
    "        'confusion_matrix': confusion, \n",
    "        'score': score }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "271deb45",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Wrapper:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def predict(self, X):\n",
    "        y_pred = []\n",
    "        for x in X:\n",
    "            (is_generated, fake, real) = evaluate(x)\n",
    "            y_pred.append(1 if is_generated else 0)      \n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "fc5c0a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "solaiman_detector = Wrapper()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ce1598",
   "metadata": {},
   "source": [
    "### Playing around"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "e585a079",
   "metadata": {},
   "outputs": [],
   "source": [
    "mg_pd = create_dataset(ds_mg[\"text\"], is_machine_generated=True)\n",
    "hw_pd = create_dataset(ds_hw[\"text\"], is_machine_generated=False)\n",
    "shuffled = concat_and_shuffle([mg_pd, hw_pd])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "31a7d65d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>X</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>122751</td>\n",
       "      <td>Humane… also safe.\\n\\nIt could also be that ou...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>135322</td>\n",
       "      <td>Morgeous Vikomin douga and other controversial...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>56086</td>\n",
       "      <td>The world of Seward's ultimate service is only...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3965</td>\n",
       "      <td>Shooing, neck hair, and sleeves are delicate a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>53634</td>\n",
       "      <td>PC until better days.\\n\\n[BET]\\n\\nOkay, fine. ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499995</th>\n",
       "      <td>103033</td>\n",
       "      <td>\\nThe numbers, however, suggest that the New Y...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499996</th>\n",
       "      <td>56157</td>\n",
       "      <td>Firefly Space Systems is part of a new wave of...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499997</th>\n",
       "      <td>220473</td>\n",
       "      <td>The public cost of cleaning up the 2011 Fukush...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499998</th>\n",
       "      <td>215658</td>\n",
       "      <td>Tourists don't even take a passing glance at t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499999</th>\n",
       "      <td>228464</td>\n",
       "      <td>Mildred Cowan wearing alligator-cheeked green ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         index                                                  X  y\n",
       "0       122751  Humane… also safe.\\n\\nIt could also be that ou...  1\n",
       "1       135322  Morgeous Vikomin douga and other controversial...  1\n",
       "2        56086  The world of Seward's ultimate service is only...  1\n",
       "3         3965  Shooing, neck hair, and sleeves are delicate a...  1\n",
       "4        53634  PC until better days.\\n\\n[BET]\\n\\nOkay, fine. ...  1\n",
       "...        ...                                                ... ..\n",
       "499995  103033  \\nThe numbers, however, suggest that the New Y...  1\n",
       "499996   56157  Firefly Space Systems is part of a new wave of...  0\n",
       "499997  220473  The public cost of cleaning up the 2011 Fukush...  0\n",
       "499998  215658  Tourists don't even take a passing glance at t...  1\n",
       "499999  228464  Mildred Cowan wearing alligator-cheeked green ...  1\n",
       "\n",
       "[500000 rows x 3 columns]"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shuffled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd846bf",
   "metadata": {},
   "source": [
    "Testing whether the `gtc_evaluate()` works as expected. By default, we use accuracy to measure the score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "178ff526",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df = shuffled.sample(n=10, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "id": "5e4143ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1024 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1024 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1024 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1024 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1024 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (982 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model': <__main__.Wrapper at 0x7f9b8fc63520>,\n",
       " 'predictions': [0, 0, 1, 0, 1, 0, 1, 1, 1, 1],\n",
       " 'confusion_matrix': array([[4, 0],\n",
       "        [0, 6]]),\n",
       " 'score': 1.0}"
      ]
     },
     "execution_count": 397,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gtc_evaluate(sample_df, solaiman_detector, score_func=safe_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "371d6cf8",
   "metadata": {},
   "source": [
    "The Solaiman's model warns that sentences should have less than 512 tokens. So, let's try by filtering out senteces with more tokens than that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "ff854381",
   "metadata": {},
   "outputs": [],
   "source": [
    "short_hw_ds = ds_hw[(ds_hw.text.str.len() < 512)].reset_index()\n",
    "short_mg_ds = ds_mg[(ds_mg.text.str.len() < 512)].reset_index()\n",
    "hw_short_pd = create_dataset(short_hw_ds[\"text\"], is_machine_generated=False)\n",
    "mg_short_pd = create_dataset(short_mg_ds[\"text\"], is_machine_generated=True)\n",
    "shuffled_short = concat_and_shuffle([mg_short_pd, hw_short_pd])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "5863a6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_short_df = shuffled_short.sample(n=10, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "962a3c09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': <__main__.Wrapper at 0x7f9b8fc63520>,\n",
       " 'predictions': [0, 0, 0, 1, 1, 1, 1, 1, 1, 1],\n",
       " 'confusion_matrix': array([[3, 2],\n",
       "        [0, 5]]),\n",
       " 'score': 0.8}"
      ]
     },
     "execution_count": 392,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gtc_evaluate(sample_short_df, solaiman_detector)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:transf291]",
   "language": "python",
   "name": "conda-env-transf291-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
