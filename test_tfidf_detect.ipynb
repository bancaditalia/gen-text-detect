{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f963291",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021f41dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"./data\"\n",
    "datasets = sorted([f for f in os.listdir(data_path) if os.path.isfile(os.path.join(data_path, f))])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b42680",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e933a050",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset_selector():\n",
    "    return widgets.Dropdown(\n",
    "        options = sorted([f for f in os.listdir(data_path) if os.path.isfile(os.path.join(data_path, f))]),\n",
    "        disabled=False,\n",
    "    )\n",
    "\n",
    "ds_select_1 = make_dataset_selector()\n",
    "ds_select_2 = make_dataset_selector()\n",
    "\n",
    "load_button = widgets.Button(\n",
    "    description='load',\n",
    "    disabled=False,\n",
    "    button_style='', # 'success', 'info', 'warning', 'danger' or ''\n",
    "    tooltip='Click to load dataset',\n",
    "    icon='download' # (FontAwesome names without the `fa-` prefix)\n",
    ")\n",
    "output = widgets.Output()\n",
    "\n",
    "def load_ds(b):\n",
    "    output.clear_output()\n",
    "    with output:\n",
    "        path_1 = os.path.join(data_path, ds_select_1.value)\n",
    "        path_2 = os.path.join(data_path, ds_select_2.value)\n",
    "        if path_1 == path_2:\n",
    "            print(\"Choose different datasets!\")\n",
    "        else:\n",
    "            print(\"loading datasets...\")\n",
    "            if os.path.exists(path_1) and os.path.exists(path_2):\n",
    "                b.value = (pd.read_json(path_1, lines = True), pd.read_json(path_2, lines = True))\n",
    "                print(f\"Datasets {ds_select_1.value} and {ds_select_2.value} loaded\")\n",
    "            else:\n",
    "                print(f\"Path does not exist!\")\n",
    "\n",
    "load_button.on_click(load_ds)\n",
    "\n",
    "\n",
    "widgets.VBox([widgets.Label(value=\"Select datasets to load:\"), \n",
    "              widgets.HBox([widgets.Label(value=\"Real text:\"), ds_select_1]),\n",
    "              widgets.HBox([widgets.Label(value=\"Fake text:\"), ds_select_2]), load_button, output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79fb286b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_real = load_button.value[0]\n",
    "df_fake = load_button.value[1]\n",
    "corpus = df_real[\"text\"].to_list() + df_fake[\"text\"].to_list()\n",
    "labels = [0 for _ in range(len(df_real))] + [1 for _ in range(len(df_fake))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d885f3",
   "metadata": {},
   "source": [
    "## Build vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af737da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nlp_engine.preprocessing import transformers as tfs\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4423dbec",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_corpus = make_pipeline(\n",
    "    tfs.WordTokenizer(), \n",
    "    tfs.WordsFilter(drop_symbols=True, drop_digits=True)\n",
    ").fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cfa4c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nlp_engine.analysis import vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e963532",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_real = vocabulary.get_vocabulary(tokenized_corpus[:len(df_real)])\n",
    "vocab_fake = vocabulary.get_vocabulary(tokenized_corpus[len(df_real):])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f00b9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_shared = vocab_real.intersection(vocab_fake)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa4433f",
   "metadata": {},
   "source": [
    "## Build baseline classifier with TF-IDF embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512ffb57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0301fced",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = make_pipeline(\n",
    "    tfs.WordTokenizer(),\n",
    "    tfs.WordsFilter(drop_symbols=True, drop_digits=True, whitelist=vocab_shared),\n",
    "    TfidfVectorizer(ngram_range=(1,3), max_features=1000000, sublinear_tf=True, tokenizer=lambda x: x, preprocessor=lambda x: x),\n",
    "    TruncatedSVD(n_components=600),\n",
    "    RandomForestClassifier(n_estimators=200, n_jobs=-1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af4c3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.fit(corpus, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd03568",
   "metadata": {},
   "source": [
    "Before running the following block, load the test datasets with the widget above and update corpus/labels with them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3602fa1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "labels_pred = pipeline.predict(corpus)\n",
    "print(classification_report(labels, labels_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-env",
   "language": "python",
   "name": "ml-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
